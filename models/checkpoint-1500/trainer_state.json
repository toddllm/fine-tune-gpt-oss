{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 55.57142857142857,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 5.132185459136963,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.0352,
      "step": 25
    },
    {
      "epoch": 1.8761904761904762,
      "grad_norm": 4.294605731964111,
      "learning_rate": 3.266666666666667e-05,
      "loss": 2.2796,
      "step": 50
    },
    {
      "epoch": 2.8,
      "grad_norm": 11.17099380493164,
      "learning_rate": 4.933333333333334e-05,
      "loss": 1.2264,
      "step": 75
    },
    {
      "epoch": 3.723809523809524,
      "grad_norm": 5.010917663574219,
      "learning_rate": 4.915789473684211e-05,
      "loss": 0.537,
      "step": 100
    },
    {
      "epoch": 4.647619047619048,
      "grad_norm": 3.7306623458862305,
      "learning_rate": 4.8280701754385964e-05,
      "loss": 0.2858,
      "step": 125
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 8.048137664794922,
      "learning_rate": 4.7403508771929825e-05,
      "loss": 0.2577,
      "step": 150
    },
    {
      "epoch": 6.495238095238095,
      "grad_norm": 4.555126667022705,
      "learning_rate": 4.652631578947369e-05,
      "loss": 0.1518,
      "step": 175
    },
    {
      "epoch": 7.419047619047619,
      "grad_norm": 3.247389078140259,
      "learning_rate": 4.564912280701755e-05,
      "loss": 0.1892,
      "step": 200
    },
    {
      "epoch": 8.342857142857143,
      "grad_norm": 3.793710231781006,
      "learning_rate": 4.4771929824561404e-05,
      "loss": 0.1287,
      "step": 225
    },
    {
      "epoch": 9.266666666666667,
      "grad_norm": 2.81070613861084,
      "learning_rate": 4.3894736842105266e-05,
      "loss": 0.1312,
      "step": 250
    },
    {
      "epoch": 10.19047619047619,
      "grad_norm": 2.1516270637512207,
      "learning_rate": 4.301754385964912e-05,
      "loss": 0.1174,
      "step": 275
    },
    {
      "epoch": 11.114285714285714,
      "grad_norm": 1.7202308177947998,
      "learning_rate": 4.214035087719298e-05,
      "loss": 0.1125,
      "step": 300
    },
    {
      "epoch": 12.038095238095238,
      "grad_norm": 1.5087828636169434,
      "learning_rate": 4.1263157894736844e-05,
      "loss": 0.1059,
      "step": 325
    },
    {
      "epoch": 12.99047619047619,
      "grad_norm": 1.4711617231369019,
      "learning_rate": 4.0385964912280706e-05,
      "loss": 0.1067,
      "step": 350
    },
    {
      "epoch": 13.914285714285715,
      "grad_norm": 1.5822428464889526,
      "learning_rate": 3.950877192982456e-05,
      "loss": 0.1016,
      "step": 375
    },
    {
      "epoch": 14.838095238095239,
      "grad_norm": 1.232827067375183,
      "learning_rate": 3.863157894736842e-05,
      "loss": 0.1016,
      "step": 400
    },
    {
      "epoch": 15.761904761904763,
      "grad_norm": 2.4742014408111572,
      "learning_rate": 3.7754385964912284e-05,
      "loss": 0.0982,
      "step": 425
    },
    {
      "epoch": 16.685714285714287,
      "grad_norm": 1.421544075012207,
      "learning_rate": 3.6877192982456146e-05,
      "loss": 0.098,
      "step": 450
    },
    {
      "epoch": 17.60952380952381,
      "grad_norm": 1.363481879234314,
      "learning_rate": 3.6e-05,
      "loss": 0.0972,
      "step": 475
    },
    {
      "epoch": 18.533333333333335,
      "grad_norm": 1.2447495460510254,
      "learning_rate": 3.512280701754386e-05,
      "loss": 0.0942,
      "step": 500
    },
    {
      "epoch": 19.457142857142856,
      "grad_norm": 1.1549124717712402,
      "learning_rate": 3.424561403508772e-05,
      "loss": 0.0938,
      "step": 525
    },
    {
      "epoch": 20.38095238095238,
      "grad_norm": 0.8301816582679749,
      "learning_rate": 3.336842105263158e-05,
      "loss": 0.0938,
      "step": 550
    },
    {
      "epoch": 21.304761904761904,
      "grad_norm": 1.0237653255462646,
      "learning_rate": 3.249122807017544e-05,
      "loss": 0.0958,
      "step": 575
    },
    {
      "epoch": 22.228571428571428,
      "grad_norm": 0.9645404815673828,
      "learning_rate": 3.16140350877193e-05,
      "loss": 0.0905,
      "step": 600
    },
    {
      "epoch": 23.152380952380952,
      "grad_norm": 0.9430714845657349,
      "learning_rate": 3.073684210526316e-05,
      "loss": 0.0956,
      "step": 625
    },
    {
      "epoch": 24.076190476190476,
      "grad_norm": 0.9032009840011597,
      "learning_rate": 2.985964912280702e-05,
      "loss": 0.095,
      "step": 650
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.160383939743042,
      "learning_rate": 2.8982456140350878e-05,
      "loss": 0.0912,
      "step": 675
    },
    {
      "epoch": 25.952380952380953,
      "grad_norm": 1.1297917366027832,
      "learning_rate": 2.810526315789474e-05,
      "loss": 0.0912,
      "step": 700
    },
    {
      "epoch": 26.876190476190477,
      "grad_norm": 1.047540545463562,
      "learning_rate": 2.7228070175438598e-05,
      "loss": 0.0909,
      "step": 725
    },
    {
      "epoch": 27.8,
      "grad_norm": 0.9359396696090698,
      "learning_rate": 2.635087719298246e-05,
      "loss": 0.091,
      "step": 750
    },
    {
      "epoch": 28.723809523809525,
      "grad_norm": 0.9537348747253418,
      "learning_rate": 2.5473684210526315e-05,
      "loss": 0.0921,
      "step": 775
    },
    {
      "epoch": 29.64761904761905,
      "grad_norm": 0.8518874645233154,
      "learning_rate": 2.4596491228070177e-05,
      "loss": 0.0896,
      "step": 800
    },
    {
      "epoch": 30.571428571428573,
      "grad_norm": 0.914286196231842,
      "learning_rate": 2.3719298245614035e-05,
      "loss": 0.0887,
      "step": 825
    },
    {
      "epoch": 31.495238095238093,
      "grad_norm": 0.7883748412132263,
      "learning_rate": 2.2842105263157897e-05,
      "loss": 0.0883,
      "step": 850
    },
    {
      "epoch": 32.41904761904762,
      "grad_norm": 0.8954548239707947,
      "learning_rate": 2.1964912280701755e-05,
      "loss": 0.0884,
      "step": 875
    },
    {
      "epoch": 33.34285714285714,
      "grad_norm": 0.7702193856239319,
      "learning_rate": 2.1087719298245613e-05,
      "loss": 0.089,
      "step": 900
    },
    {
      "epoch": 34.266666666666666,
      "grad_norm": 0.8002495765686035,
      "learning_rate": 2.0210526315789475e-05,
      "loss": 0.0886,
      "step": 925
    },
    {
      "epoch": 35.19047619047619,
      "grad_norm": 0.9793407917022705,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0892,
      "step": 950
    },
    {
      "epoch": 36.114285714285714,
      "grad_norm": 0.6989638805389404,
      "learning_rate": 1.8456140350877195e-05,
      "loss": 0.0884,
      "step": 975
    },
    {
      "epoch": 37.03809523809524,
      "grad_norm": 0.8251039981842041,
      "learning_rate": 1.7578947368421054e-05,
      "loss": 0.0872,
      "step": 1000
    },
    {
      "epoch": 37.99047619047619,
      "grad_norm": 0.779028594493866,
      "learning_rate": 1.6701754385964912e-05,
      "loss": 0.0871,
      "step": 1025
    },
    {
      "epoch": 38.91428571428571,
      "grad_norm": 0.8142603635787964,
      "learning_rate": 1.5824561403508774e-05,
      "loss": 0.0869,
      "step": 1050
    },
    {
      "epoch": 39.838095238095235,
      "grad_norm": 0.8471870422363281,
      "learning_rate": 1.4947368421052632e-05,
      "loss": 0.0878,
      "step": 1075
    },
    {
      "epoch": 40.76190476190476,
      "grad_norm": 1.4109395742416382,
      "learning_rate": 1.4070175438596492e-05,
      "loss": 0.0873,
      "step": 1100
    },
    {
      "epoch": 41.68571428571428,
      "grad_norm": 0.9350773096084595,
      "learning_rate": 1.3192982456140352e-05,
      "loss": 0.0872,
      "step": 1125
    },
    {
      "epoch": 42.60952380952381,
      "grad_norm": 0.877630352973938,
      "learning_rate": 1.231578947368421e-05,
      "loss": 0.0856,
      "step": 1150
    },
    {
      "epoch": 43.53333333333333,
      "grad_norm": 0.7833105325698853,
      "learning_rate": 1.143859649122807e-05,
      "loss": 0.0864,
      "step": 1175
    },
    {
      "epoch": 44.457142857142856,
      "grad_norm": 1.058982253074646,
      "learning_rate": 1.056140350877193e-05,
      "loss": 0.087,
      "step": 1200
    },
    {
      "epoch": 45.38095238095238,
      "grad_norm": 0.8912797570228577,
      "learning_rate": 9.68421052631579e-06,
      "loss": 0.0845,
      "step": 1225
    },
    {
      "epoch": 46.304761904761904,
      "grad_norm": 0.8968197107315063,
      "learning_rate": 8.807017543859649e-06,
      "loss": 0.087,
      "step": 1250
    },
    {
      "epoch": 47.22857142857143,
      "grad_norm": 0.8341395854949951,
      "learning_rate": 7.929824561403509e-06,
      "loss": 0.0849,
      "step": 1275
    },
    {
      "epoch": 48.15238095238095,
      "grad_norm": 0.7124125361442566,
      "learning_rate": 7.052631578947369e-06,
      "loss": 0.0862,
      "step": 1300
    },
    {
      "epoch": 49.076190476190476,
      "grad_norm": 0.8497567772865295,
      "learning_rate": 6.175438596491228e-06,
      "loss": 0.0862,
      "step": 1325
    },
    {
      "epoch": 50.0,
      "grad_norm": 1.737979531288147,
      "learning_rate": 5.2982456140350875e-06,
      "loss": 0.0847,
      "step": 1350
    },
    {
      "epoch": 50.95238095238095,
      "grad_norm": 1.2453984022140503,
      "learning_rate": 4.4210526315789476e-06,
      "loss": 0.0843,
      "step": 1375
    },
    {
      "epoch": 51.87619047619047,
      "grad_norm": 0.8049401044845581,
      "learning_rate": 3.5438596491228068e-06,
      "loss": 0.0857,
      "step": 1400
    },
    {
      "epoch": 52.8,
      "grad_norm": 0.8067581057548523,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0833,
      "step": 1425
    },
    {
      "epoch": 53.72380952380952,
      "grad_norm": 0.9619413018226624,
      "learning_rate": 1.7894736842105262e-06,
      "loss": 0.0855,
      "step": 1450
    },
    {
      "epoch": 54.647619047619045,
      "grad_norm": 0.8691596984863281,
      "learning_rate": 9.12280701754386e-07,
      "loss": 0.083,
      "step": 1475
    },
    {
      "epoch": 55.57142857142857,
      "grad_norm": 0.8915718197822571,
      "learning_rate": 3.508771929824561e-08,
      "loss": 0.0834,
      "step": 1500
    }
  ],
  "logging_steps": 25,
  "max_steps": 1500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 56,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.079466824636851e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
